{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 2\n"
     ]
    }
   ],
   "source": [
    "# Running on GPU?\n",
    "import setGPU\n",
    "\n",
    "import getpass\n",
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get permission to access EOS (Insert your NICE password)\n",
    "os.system(\"echo %s | kinit\" % getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input, Dense, Lambda, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.activations import sigmoid, linear, relu\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDs  = {1: 'BTagCSV',\n",
    "        2: 'BTagMu',\n",
    "        3: 'Charmonium',\n",
    "        4: 'DisplacedJet',\n",
    "        5: 'DoubleEG',\n",
    "        6: 'DoubleMuon',\n",
    "        7: 'DoubleMuonLowMass',\n",
    "        8: 'FSQJets',\n",
    "        9: 'HighMultiplicityEOF',\n",
    "        10: 'HTMHT',\n",
    "        11: 'JetHT',\n",
    "        12: 'MET',\n",
    "        13: 'MinimumBias',\n",
    "        14: 'MuonEG',\n",
    "        15: 'MuOnia',\n",
    "        16: 'NoBPTX',\n",
    "        17: 'SingleElectron',\n",
    "        18: 'SingleMuon',\n",
    "        19: 'SinglePhoton',\n",
    "        20: 'Tau',\n",
    "        21: 'ZeroBias'}\n",
    "\n",
    "# Select PD\n",
    "nPD = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = \"/eos/cms/store/user/fsiroky/consistentlumih5/\"\n",
    "label_file = \"/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/JetHT.json\"\n",
    "model_directory = \"/eos/user/t/tkrzyzek/autoencoder/standard/\"\n",
    "model_name = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(directory, pds, npd, typeof, extension):\n",
    "    files = []\n",
    "    parts = [\"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "    for p in parts:\n",
    "        files.append(\"%s%s_%s_%s%s\" % (directory, pds[npd], p, typeof, extension))\n",
    "    return files\n",
    "\n",
    "files = get_file_list(data_directory, PDs, nPD, \"background\", \".h5\")\n",
    "files = files + get_file_list(data_directory, PDs, nPD, \"signal\", \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load good and bad jets\n",
    "def get_data(files):\n",
    "    readout = np.empty([0,2813])\n",
    "    \n",
    "    for file in files:\n",
    "        jet = file.split(\"/\")[-1][:-3]\n",
    "        print(\"Reading: %s\" % jet)\n",
    "        try:\n",
    "            h5file = h5py.File(file, \"r\")\n",
    "            readout = np.concatenate((readout, h5file[jet][:]), axis=0)\n",
    "        except OSError as error:\n",
    "            print(\"This Primary Dataset doesn't have %s. %s\" % (jet, error))\n",
    "            continue\n",
    "\n",
    "    return readout\n",
    "\n",
    "data = pd.DataFrame(get_data(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"run\"] = data[2807].astype(int)\n",
    "data[\"lumi\"] = data[2808].astype(int)\n",
    "data[\"inst_lumi\"] = data[2809].astype(float)\n",
    "\n",
    "# Drop unnecessary meta data\n",
    "data.drop([2807, 2808, 2809, 2810, 2811, 2812], axis=1, inplace=True)\n",
    "\n",
    "# Sort by runID and then by lumiID\n",
    "data = data.sort_values([\"run\", \"lumi\"], ascending=[True,True])\n",
    "\n",
    "# Reset index\n",
    "data = data.reset_index(drop=True)  \n",
    "\n",
    "runIDs  = data[\"run\"].astype(int)\n",
    "lumiIDs = data[\"lumi\"].astype(int)\n",
    "luminosity = data[\"inst_lumi\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply labels\n",
    "output_json = json.load(open(label_file))\n",
    "\n",
    "def json_checker(json_file, orig_runid, orig_lumid):\n",
    "    try:\n",
    "        for i in json_file[str(int(orig_runid))]:\n",
    "            if orig_lumid >= i[0] and orig_lumid <= i[1]:\n",
    "                return 0\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "def add_flags(sample):\n",
    "    return json_checker(output_json, sample[\"run\"], sample[\"lumi\"])\n",
    "\n",
    "data[\"label\"] = data.apply(add_flags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "SPLIT_FACTOR = 0.1\n",
    "\n",
    "split = round(SPLIT_FACTOR*len(data))\n",
    "\n",
    "runIDs = runIDs[split:]\n",
    "lumiIDs = lumiIDs[split:]\n",
    "luminosity = luminosity[split:]\n",
    "\n",
    "train = data.iloc[:split]\n",
    "before = train.shape[0]\n",
    "X_train = train.iloc[:, 0:2806]\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "test = data.iloc[split:]\n",
    "X_test = test.iloc[:, 0:2806]\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "\n",
    "# Train only on good\n",
    "X_train = X_train[y_train == 0]\n",
    "X_train_norm = X_train_norm[y_train == 0]\n",
    "\n",
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "x = Dense(2000, kernel_regularizer=l1_l2(10e-5))(input_layer)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(1000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(500, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(1000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(2000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(input_dim)(x)\n",
    "x = linear(x)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adamm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\",\n",
    "                              patience=32,\n",
    "                              verbose=True,\n",
    "                              mode=\"auto\")\n",
    "\n",
    "autoencoder.compile(optimizer=adamm, loss='mean_squared_error')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint((\"%s%s.h5\" % (model_directory, model_name)),\n",
    "                                      monitor=\"val_loss\",\n",
    "                                      verbose=False,\n",
    "                                      save_best_only=True,\n",
    "                                      mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train_norm,\n",
    "                X_train_norm,\n",
    "                epochs=128,\n",
    "                batch_size=256,\n",
    "                validation_split=0.25,\n",
    "                verbose=2,\n",
    "                callbacks=[early_stopper, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reload saved model\n",
    "autoencoder = load_model(\"%s%s.h5\" % (model_directory, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "predictions = autoencoder.predict(X_test_norm)\n",
    "\n",
    "def get_error_df(X_test, predictions, mode=\"allmean\", n_highest = 100):\n",
    "    \n",
    "    if mode == \"allmean\":\n",
    "        return np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "    \n",
    "    elif mode == \"topn\":\n",
    "        temp = np.partition(-np.power(X_test - predictions, 2), n_highest)\n",
    "        result = -temp[:,:n_highest]\n",
    "        return np.mean(result, axis=1)\n",
    "    \n",
    "    elif mode == \"perobj\":\n",
    "        mses = []\n",
    "        for l in legend:\n",
    "            mse = np.mean(\n",
    "                np.power(X_test[:,l[\"start\"]:l[\"end\"]] - predictions[:,l[\"start\"]:l[\"end\"]], 2),\n",
    "                axis=1)\n",
    "            mses.append(mse)\n",
    "     \n",
    "        return np.maximum.reduce(mses)\n",
    "    \n",
    "ae_error = get_error_df(X_test_norm, predictions, mode=\"topn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_pred_baseline = pickle.load(open('/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01/ae_pred.p', \"rb\"))\n",
    "ae_error_baseline = get_error_df(X_test_norm, ae_pred_baseline, mode=\"topn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make ROC_curve\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score                          \n",
    "\n",
    "def get_roc_curve(label, scores, names):\n",
    "    \"\"\"Generates ROC Curves for a given array\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        fpr, tpr, thresholds = roc_curve(label, scores[i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr,\n",
    "                 tpr,\n",
    "                 linewidth=3,\n",
    "                 #linestyle=line_styles[0],\n",
    "                 label=(\"%s AUC: %s\" % (names[i], roc_auc)))\n",
    "        \n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylabel(\"Sensitivity (TPR)\")\n",
    "    plt.xlabel(\"Fall-out (TNR)\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlim([0, 1])\n",
    "    plt.title('ROC curves for AE with batchnorm')\n",
    "    plt.show();\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "get_roc_curve(y_test, [ae_error, ae_error_baseline], ['AE with cleaned data', 'AE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_directory = \"/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_error, open(model_directory + \"ae_error_cleaned_4e7.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(predictions, open(model_directory + \"pred_cleaned_4e7.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_vs_feature2(y_val, x_val, y_class, y_name=\"\", x_name=\"\", selected=[], linear=False,\n",
    "                    x_lim=None, y_lim=None, title=\"\"):\n",
    "\n",
    "    fig, (ax1) = plt.subplots(1, 1, sharex=True)\n",
    "    \n",
    "    ax = [ax1]\n",
    "    ax1.set_title(title)\n",
    "    \n",
    "    for i in range(1):\n",
    "        df = pd.DataFrame({'y_val': y_val[i],\n",
    "                           'x_val': x_val,\n",
    "                           'y_class': y_class})\n",
    "\n",
    "        groups = df.groupby('y_class')\n",
    "\n",
    "        for name, group in groups:\n",
    "            ax[i].plot(group.x_val, \n",
    "                    group.y_val,\n",
    "                    color=\"r\" if name == 1 else \"g\",\n",
    "                    marker='o',\n",
    "                    ms=2,\n",
    "                    linestyle='',\n",
    "                    label= \"Bad\" if name == 1 else \"Good\")\n",
    "\n",
    "        for i in selected:\n",
    "            ax[i].plot(x_val[i],\n",
    "                    y_val[i],\n",
    "                    color=\"g\",\n",
    "                    marker='o',\n",
    "                    ms=4,\n",
    "                    linestyle='')\n",
    "\n",
    "        ax[i].legend()\n",
    "        if not linear:\n",
    "            ax[i].set_yscale('log')\n",
    "        if x_lim:\n",
    "            ax[i].set_xlim(x_lim[0], x_lim[1])\n",
    "        if y_lim:\n",
    "            ax[i].set_ylim(y_lim[0], y_lim[1])\n",
    "        ax[i].set_ylabel(y_name[i])\n",
    "        ax[i].grid()\n",
    "    plt.xlabel(x_name)\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_var(legend, ae_pred):\n",
    "    for var in legend:\n",
    "            print(\"###########################################################################\")\n",
    "            print(var['name'])\n",
    "            print(\"###########################################################################\")\n",
    "\n",
    "            X_var = X.iloc[:, var['start'] : var['end']+1]\n",
    "            ae_pred_var = ae_pred[:, var['start'] : var['end']+1]\n",
    "\n",
    "            mean = np.mean(X_var, axis=1)\n",
    "            mean_abs = np.mean(np.abs(X_var), axis=1)\n",
    "            sd = np.std(X_var, axis=1)\n",
    "            \n",
    "            ae_mean = np.mean(ae_pred_var, axis=1)\n",
    "            ae_mean_abs = np.mean(np.abs(ae_pred_var), axis=1)\n",
    "            ae_sd = np.std(ae_pred_var, axis=1)\n",
    "\n",
    "            # No scale set\n",
    "            pred_vs_feature2([mean, mean_abs, sd],\n",
    "                            luminosity, \n",
    "                            y_test, #!!!\n",
    "                            [var['name'], \n",
    "                             var['name'] + \" abs\"],\n",
    "                            \"Luminosity\",\n",
    "                            title=var['name'],\n",
    "                            x_lim=(0, 0.35),\n",
    "#                             y_lim=(-5, 5),\n",
    "                            linear=True)\n",
    "            \n",
    "            pred_vs_feature2([ae_mean, ae_mean_abs, ae_sd],\n",
    "                            luminosity, \n",
    "                            y_test, #!!!\n",
    "                            [var['name'], \n",
    "                             var['name'] + \" AE pred\"],\n",
    "                            \"Luminosity\",\n",
    "                            title=var['name'] + \" AE pred\",\n",
    "                            x_lim=(0, 0.35),\n",
    "#                             y_lim=(-5, 5),\n",
    "                            linear=True)\n",
    "            \n",
    "            # With bounds [-5, 5]\n",
    "            pred_vs_feature2([mean, mean_abs, sd],\n",
    "                            luminosity, \n",
    "                            y_test, #!!!\n",
    "                            [var['name'], \n",
    "                             var['name'] + \" abs\"],\n",
    "                            \"Luminosity\",\n",
    "                            title=var['name'],\n",
    "                            x_lim=(0, 0.35),\n",
    "                            y_lim=(-5, 5),\n",
    "                            linear=True)\n",
    "            \n",
    "            pred_vs_feature2([ae_mean, ae_mean_abs, ae_sd],\n",
    "                            luminosity, \n",
    "                            y_test, #!!!\n",
    "                            [var['name'], \n",
    "                             var['name'] + \" AE pred\"],\n",
    "                            \"Luminosity\",\n",
    "                            title=var['name'] + \" AE pred\",\n",
    "                            x_lim=(0, 0.35),\n",
    "                            y_lim=(-5, 5),\n",
    "                            linear=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start_legend = 1918 #nvtx\n",
    "start_legend = 1414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_legend = [{'start': start_legend, 'end': start_legend, 'name': 'Mean'},\n",
    "              {'start': start_legend+1, 'end': start_legend+1, 'name': 'RMS'},\n",
    "              {'start': start_legend+2, 'end': start_legend+2, 'name': 'Q1'},\n",
    "              {'start': start_legend+3, 'end': start_legend+3, 'name': 'Q2'},\n",
    "              {'start': start_legend+4, 'end': start_legend+4, 'name': 'Q3'},\n",
    "              {'start': start_legend+5, 'end': start_legend+5, 'name': 'Q4'},\n",
    "              {'start': start_legend+6, 'end': start_legend+6, 'name': 'Q5'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plot_var(var_legend, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
