{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    }
   ],
   "source": [
    "# Running on GPU?\n",
    "import setGPU\n",
    "\n",
    "import getpass\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "# Get permission to access EOS (Insert your NICE password)\n",
    "os.system(\"echo %s | kinit\" % getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input, Dense, Lambda, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.activations import sigmoid, linear, relu\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDs  = {1: 'BTagCSV',\n",
    "        2: 'BTagMu',\n",
    "        3: 'Charmonium',\n",
    "        4: 'DisplacedJet',\n",
    "        5: 'DoubleEG',\n",
    "        6: 'DoubleMuon',\n",
    "        7: 'DoubleMuonLowMass',\n",
    "        8: 'FSQJets',\n",
    "        9: 'HighMultiplicityEOF',\n",
    "        10: 'HTMHT',\n",
    "        11: 'JetHT',\n",
    "        12: 'MET',\n",
    "        13: 'MinimumBias',\n",
    "        14: 'MuonEG',\n",
    "        15: 'MuOnia',\n",
    "        16: 'NoBPTX',\n",
    "        17: 'SingleElectron',\n",
    "        18: 'SingleMuon',\n",
    "        19: 'SinglePhoton',\n",
    "        20: 'Tau',\n",
    "        21: 'ZeroBias'}\n",
    "\n",
    "# Select PD\n",
    "nPD = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "legend = [{\"name\": 'pf_jets', \"start\": 0, \"end\": 776},\n",
    "          {\"name\": 'cal_jet_mets', \"start\": 777, \"end\": 944},\n",
    "          {\"name\": 'pho', \"start\": 945, \"end\": 1280},\n",
    "          {\"name\": 'muons', \"start\": 1281, \"end\": 1784},\n",
    "          {\"name\": 'pf_jets2', \"start\": 1785, \"end\": 1889},\n",
    "          {\"name\": 'pf_mets', \"start\": 1890, \"end\": 1917},\n",
    "          {\"name\": 'nvtx', \"start\": 1918, \"end\": 1924},\n",
    "          {\"name\": 'cal_jet_mets2', \"start\": 1925},\n",
    "          {\"name\": 'sc', \"start\": 2037, \"end\": 2127},\n",
    "          {\"name\": 'cc', \"start\": 2128, \"end\": 2169},\n",
    "          {\"name\": 'pho2', \"start\": 2170, \"end\": 2365},\n",
    "          {\"name\": 'muons2', \"start\": 2366, \"end\": 2491},\n",
    "          {\"name\": 'ebs', \"start\": 2492, \"end\": 2701},\n",
    "          {\"name\": 'hbhef', \"start\": 2702, \"end\": 2764},\n",
    "          {\"name\": 'presh', \"start\": 2765, \"end\": 2806},\n",
    "          {\"name\": 'inst_lumi', \"start\": 2807, \"end\": 2808}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature description\n",
    "feature_names = ['qPFJetPt', 'qPFJetEta', 'qPFJetPhi', 'qPFJet0Pt', 'qPFJet1Pt', 'qPFJet2Pt', 'qPFJet3Pt', 'qPFJet4Pt', 'qPFJet5Pt', 'qPFJet0Eta', 'qPFJet1Eta', 'qPFJet2Eta', 'qPFJet3Eta', 'qPFJet4Eta', 'qPFJet5Eta', 'qPFJet0Phi', 'qPFJet1Phi', 'qPFJet2Phi', 'qPFJet3Phi', 'qPFJet4Phi', 'qPFJet5Phi', 'qPFJet4CHS0Pt', 'qPFJet4CHS1Pt', 'qPFJet4CHS2Pt', 'qPFJet4CHS3Pt', 'qPFJet4CHS4Pt', 'qPFJet4CHS5Pt', 'qPFJet4CHS0Eta', 'qPFJet4CHS1Eta', 'qPFJet4CHS2Eta', 'qPFJet4CHS3Eta', 'qPFJet4CHS4Eta', 'qPFJet4CHS5Eta', 'qPFJet4CHS0Phi', 'qPFJet4CHS1Phi', 'qPFJet4CHS2Phi', 'qPFJet4CHS3Phi', 'qPFJet4CHS4Phi', 'qPFJet4CHS5Phi', 'qPFJet8CHS0Pt', 'qPFJet8CHS1Pt', 'qPFJet8CHS2Pt', 'qPFJet8CHS3Pt', 'qPFJet8CHS4Pt', 'qPFJet8CHS5Pt', 'qPFJet8CHS0Eta', 'qPFJet8CHS1Eta', 'qPFJet8CHS2Eta', 'qPFJet8CHS3Eta', 'qPFJet8CHS4Eta', 'qPFJet8CHS5Eta', 'qPFJet8CHS0Phi', 'qPFJet8CHS1Phi', 'qPFJet8CHS2Phi', 'qPFJet8CHS3Phi', 'qPFJet8CHS4Phi', 'qPFJet8CHS5Phi', 'qPFJetEI0Pt', 'qPFJetEI1Pt', 'qPFJetEI2Pt', 'qPFJetEI3Pt', 'qPFJetEI4Pt', 'qPFJetEI5Pt', 'qPFJetEI0Eta', 'qPFJetEI1Eta', 'qPFJetEI2Eta', 'qPFJetEI3Eta', 'qPFJetEI4Eta', 'qPFJetEI5Eta', 'qPFJetEI0Phi', 'qPFJetEI1Phi', 'qPFJetEI2Phi', 'qPFJetEI3Phi', 'qPFJetEI4Phi', 'qPFJetEI5Phi', 'qPFJet8CHSSD0Pt', 'qPFJet8CHSSD1Pt', 'qPFJet8CHSSD2Pt', 'qPFJet8CHSSD3Pt', 'qPFJet8CHSSD4Pt', 'qPFJet8CHSSD5Pt', 'qPFJet8CHSSD0Eta', 'qPFJet8CHSSD1Eta', 'qPFJet8CHSSD2Eta', 'qPFJet8CHSSD3Eta', 'qPFJet8CHSSD4Eta', 'qPFJet8CHSSD5Eta', 'qPFJet8CHSSD0Phi', 'qPFJet8CHSSD1Phi', 'qPFJet8CHSSD2Phi', 'qPFJet8CHSSD3Phi', 'qPFJet8CHSSD4Phi', 'qPFJet8CHSSD5Phi', 'qPFJetTopCHS0Pt', 'qPFJetTopCHS1Pt', 'qPFJetTopCHS2Pt', 'qPFJetTopCHS3Pt', 'qPFJetTopCHS4Pt', 'qPFJetTopCHS5Pt', 'qPFJetTopCHS0Eta', 'qPFJetTopCHS1Eta', 'qPFJetTopCHS2Eta', 'qPFJetTopCHS3Eta', 'qPFJetTopCHS4Eta', 'qPFJetTopCHS5Eta', 'qPFJetTopCHS0Phi', 'qPFJetTopCHS1Phi', 'qPFJetTopCHS2Phi', 'qPFJetTopCHS3Phi', 'qPFJetTopCHS4Phi', 'qPFJetTopCHS5Phi', 'qCalJet0Pt', 'qCalJet1Pt', 'qCalJet2Pt', 'qCalJet3Pt', 'qCalJet4Pt', 'qCalJet5Pt', 'qCalJet0Eta', 'qCalJet1Eta', 'qCalJet2Eta', 'qCalJet3Eta', 'qCalJet4Eta', 'qCalJet5Eta', 'qCalJet0Phi', 'qCalJet1Phi', 'qCalJet2Phi', 'qCalJet3Phi', 'qCalJet4Phi', 'qCalJet5Phi', 'qCalJet0En', 'qCalJet1En', 'qCalJet2En', 'qCalJet3En', 'qCalJet4En', 'qCalJet5En', 'qPho0Pt', 'qPho1Pt', 'qPho2Pt', 'qPho3Pt', 'qPho4Pt', 'qPho5Pt', 'qPho0Eta', 'qPho1Eta', 'qPho2Eta', 'qPho3Eta', 'qPho4Eta', 'qPho5Eta', 'qPho0Phi', 'qPho1Phi', 'qPho2Phi', 'qPho3Phi', 'qPho4Phi', 'qPho5Phi', 'qPho0En', 'qPho1En', 'qPho2En', 'qPho3En', 'qPho4En', 'qPho5En', 'qgedPho0Pt', 'qgedPho1Pt', 'qgedPho2Pt', 'qgedPho3Pt', 'qgedPho4Pt', 'qgedPho5Pt', 'qgedPho0Eta', 'qgedPho1Eta', 'qgedPho2Eta', 'qgedPho3Eta', 'qgedPho4Eta', 'qgedPho5Eta', 'qgedPho0Phi', 'qgedPho1Phi', 'qgedPho2Phi', 'qgedPho3Phi', 'qgedPho4Phi', 'qgedPho5Phi', 'qgedPho0En', 'qgedPho1En', 'qgedPho2En', 'qgedPho3En', 'qgedPho4En', 'qgedPho5En', 'qMu0Pt', 'qMu1Pt', 'qMu2Pt', 'qMu3Pt', 'qMu4Pt', 'qMu5Pt', 'qMu0Eta', 'qMu1Eta', 'qMu2Eta', 'qMu3Eta', 'qMu4Eta', 'qMu5Eta', 'qMu0Phi', 'qMu1Phi', 'qMu2Phi', 'qMu3Phi', 'qMu4Phi', 'qMu5Phi', 'qMu0En', 'qMu1En', 'qMu2En', 'qMu3En', 'qMu4En', 'qMu5En', 'qMuCosm0Pt', 'qMuCosm1Pt', 'qMuCosm2Pt', 'qMuCosm3Pt', 'qMuCosm4Pt', 'qMuCosm5Pt', 'qMuCosm0Eta', 'qMuCosm1Eta', 'qMuCosm2Eta', 'qMuCosm3Eta', 'qMuCosm4Eta', 'qMuCosm5Eta', 'qMuCosm0Phi', 'qMuCosm1Phi', 'qMuCosm2Phi', 'qMuCosm3Phi', 'qMuCosm4Phi', 'qMuCosm5Phi', 'qMuCosm0En', 'qMuCosm1En', 'qMuCosm2En', 'qMuCosm3En', 'qMuCosm4En', 'qMuCosm5En', 'qMuCosmLeg0Pt', 'qMuCosmLeg1Pt', 'qMuCosmLeg2Pt', 'qMuCosmLeg3Pt', 'qMuCosmLeg4Pt', 'qMuCosmLeg5Pt', 'qMuCosmLeg0Eta', 'qMuCosmLeg1Eta', 'qMuCosmLeg2Eta', 'qMuCosmLeg3Eta', 'qMuCosmLeg4Eta', 'qMuCosmLeg5Eta', 'qMuCosmLeg0Phi', 'qMuCosmLeg1Phi', 'qMuCosmLeg2Phi', 'qMuCosmLeg3Phi', 'qMuCosmLeg4Phi', 'qMuCosmLeg5Phi', 'qMuCosmLeg0En', 'qMuCosmLeg1En', 'qMuCosmLeg2En', 'qMuCosmLeg3En', 'qMuCosmLeg4En', 'qMuCosmLeg5En', 'qPFJet4CHSPt', 'qPFJet4CHSEta', 'qPFJet4CHSPhi', 'qPFJet8CHSPt', 'qPFJet8CHSEta', 'qPFJet8CHSPhi', 'qPFJetEIPt', 'qPFJetEIEta', 'qPFJetEIPhi', 'qPFJet8CHSSDPt', 'qPFJet8CHSSDEta', 'qPFJet8CHSSDPhi', 'qPFJetTopCHSPt', 'qPFJetTopCHSEta', 'qPFJetTopCHSPhi', 'qPFChMetPt', 'qPFChMetPhi', 'qPFMetPt', 'qPFMetPhi', 'qNVtx', 'qCalJetPt', 'qCalJetEta', 'qCalJetPhi', 'qCalJetEn', 'qCalMETPt', 'qCalMETPhi', 'qCalMETEn', 'qCalMETBEPt', 'qCalMETBEPhi', 'qCalMETBEEn', 'qCalMETBEFOPt', 'qCalMETBEFOPhi', 'qCalMETBEFOEn', 'qCalMETMPt', 'qCalMETMPhi', 'qCalMETMEn', 'qSCEn', 'qSCEta', 'qSCPhi', 'qSCEtaWidth', 'qSCPhiWidth', 'qSCEnhfEM', 'qSCEtahfEM', 'qSCPhihfEM', 'qSCEn5x5', 'qSCEta5x5', 'qSCPhi5x5', 'qSCEtaWidth5x5', 'qSCPhiWidth5x5', 'qCCEn', 'qCCEta', 'qCCPhi', 'qCCEn5x5', 'qCCEta5x5', 'qCCPhi5x5', 'qPhoPt', 'qPhoEta', 'qPhoPhi', 'qPhoEn_', 'qPhoe1x5_', 'qPhoe2x5_', 'qPhoe3x3_', 'qPhoe5x5_', 'qPhomaxenxtal_', 'qPhosigmaeta_', 'qPhosigmaIeta_', 'qPhor1x5_', 'qPhor2x5_', 'qPhor9_', 'qgedPhoPt', 'qgedPhoEta', 'qgedPhoPhi', 'qgedPhoEn_', 'qgedPhoe1x5_', 'qgedPhoe2x5_', 'qgedPhoe3x3_', 'qgedPhoe5x5_', 'qgedPhomaxenxtal_', 'qgedPhosigmaeta_', 'qgedPhosigmaIeta_', 'qgedPhor1x5_', 'qgedPhor2x5_', 'qgedPhor9_', 'qMuPt', 'qMuEta', 'qMuPhi', 'qMuEn_', 'qMuCh_', 'qMuChi2_', 'qMuCosmPt', 'qMuCosmEta', 'qMuCosmPhi', 'qMuCosmEn_', 'qMuCosmCh_', 'qMuCosmChi2_', 'qMuCosmLegPt', 'qMuCosmLegEta', 'qMuCosmLegPhi', 'qMuCosmLegEn_', 'qMuCosmLegCh_', 'qMuCosmLegChi2_', 'qSigmaIEta', 'qSigmaIPhi', 'qr9', 'qHadOEm', 'qdrSumPt', 'qdrSumEt', 'qeSCOP', 'qecEn', 'qUNSigmaIEta', 'qUNSigmaIPhi', 'qUNr9', 'qUNHadOEm', 'qUNdrSumPt', 'qUNdrSumEt', 'qUNeSCOP', 'qUNecEn', 'qEBenergy', 'qEBtime', 'qEBchi2', 'qEBiEta', 'qEBiPhi', 'qEEenergy', 'qEEtime', 'qEEchi2', 'qEEix', 'qEEiy', 'qESenergy', 'qEStime', 'qESix', 'qESiy', 'qHBHEenergy', 'qHBHEtime', 'qHBHEauxe', 'qHBHEieta', 'qHBHEiphi', 'qHFenergy', 'qHFtime', 'qHFieta', 'qHFiphi', 'qPreShEn', 'qPreShEta', 'qPreShPhi', 'qPreShYEn', 'qPreShYEta', 'qPreShYPhi', 'inst_luminosity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = \"/eos/cms/store/user/fsiroky/consistentlumih5/\"\n",
    "label_file = \"/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/JetHT.json\"\n",
    "pileup_file = \"/afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions16/13TeV/PileUp/pileup_latest.txt\"\n",
    "# model_directory = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_bottleneck/\"\n",
    "model_directory = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_w_pileup/\"\n",
    "# model_directory = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_w_pileup_no_bottleneck/\"\n",
    "# model_directory = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_no_pileup_no_bottleneck/\"\n",
    "model_name = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(directory, pds, npd, typeof, extension):\n",
    "    files = []\n",
    "    parts = [\"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "    for p in parts:\n",
    "        files.append(\"%s%s_%s_%s%s\" % (directory, pds[npd], p, typeof, extension))\n",
    "    return files\n",
    "\n",
    "files = get_file_list(data_directory, PDs, nPD, \"background\", \".h5\")\n",
    "files = files + get_file_list(data_directory, PDs, nPD, \"signal\", \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: JetHT_C_background\n",
      "Reading: JetHT_D_background\n",
      "Reading: JetHT_E_background\n",
      "Reading: JetHT_F_background\n",
      "Reading: JetHT_G_background\n",
      "Reading: JetHT_H_background\n",
      "Reading: JetHT_C_signal\n",
      "Reading: JetHT_D_signal\n",
      "Reading: JetHT_E_signal\n",
      "Reading: JetHT_F_signal\n",
      "Reading: JetHT_G_signal\n",
      "Reading: JetHT_H_signal\n"
     ]
    }
   ],
   "source": [
    "# Load good and bad jets\n",
    "def get_data(files):\n",
    "    readout = np.empty([0,2813])\n",
    "    \n",
    "    for file in files:\n",
    "        jet = file.split(\"/\")[-1][:-3]\n",
    "        print(\"Reading: %s\" % jet)\n",
    "        try:\n",
    "            h5file = h5py.File(file, \"r\")\n",
    "            readout = np.concatenate((readout, h5file[jet][:]), axis=0)\n",
    "        except OSError as error:\n",
    "            print(\"This Primary Dataset doesn't have %s. %s\" % (jet, error))\n",
    "            continue\n",
    "\n",
    "    return readout\n",
    "\n",
    "data = pd.DataFrame(get_data(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"run\"] = data[2807].astype(int)\n",
    "data[\"lumi\"] = data[2808].astype(int)\n",
    "data[\"inst_lumi\"] = data[2809].astype(float)\n",
    "\n",
    "# Drop unnecessary meta data\n",
    "data.drop([2808, 2809, 2810, 2811, 2812], axis=1, inplace=True)\n",
    "\n",
    "# Append inst. luminosity at the end as well\n",
    "data[2807] = data[\"inst_lumi\"]\n",
    "\n",
    "# Sort by runID and then by lumiID\n",
    "data = data.sort_values([\"run\", \"lumi\"], ascending=[True,True])\n",
    "\n",
    "# Reset index\n",
    "data = data.reset_index(drop=True)  \n",
    "\n",
    "runIDs  = data[\"run\"].astype(int)\n",
    "lumiIDs = data[\"lumi\"].astype(int)\n",
    "luminosity = data[\"inst_lumi\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply labels\n",
    "output_json = json.load(open(label_file))\n",
    "\n",
    "def json_checker(json_file, orig_runid, orig_lumid):\n",
    "    try:\n",
    "        for i in json_file[str(int(orig_runid))]:\n",
    "            if orig_lumid >= i[0] and orig_lumid <= i[1]:\n",
    "                return 0\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "def add_flags(sample):\n",
    "    return json_checker(output_json, sample[\"run\"], sample[\"lumi\"])\n",
    "\n",
    "data[\"label\"] = data.apply(add_flags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(pileup_file) as f:\n",
    "    pileup = json.load(f)\n",
    "\n",
    "def pileup_from_json(json_file, orig_runid, orig_lumid):\n",
    "    try:\n",
    "        for i in json_file[str(int(orig_runid))]:\n",
    "            if orig_lumid == i[0]:\n",
    "                return i[3]\n",
    "    except KeyError:\n",
    "        print('key error')\n",
    "    return 1\n",
    "\n",
    "def add_pileup(sample):\n",
    "    return pileup_from_json(pileup, sample[\"run\"], sample[\"lumi\"])\n",
    "\n",
    "data[\"pileup\"] = data.apply(add_pileup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[2808] = data[\"pileup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "TRAIN_FROM = round(0.8*len(data))\n",
    "TRAIN_TO = round(0.9*len(data))\n",
    "TEST_FROM = round(0.9*len(data))\n",
    "\n",
    "train = data.iloc[TRAIN_FROM:TRAIN_TO]\n",
    "X_train = pd.concat([train.iloc[:, :2808], train[2808]], axis=1)\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "# Adding bad data to test set\n",
    "test = pd.concat([data.iloc[TEST_FROM:], data[:TEST_FROM][data['label'] == 1]]) \n",
    "X_test = pd.concat([test.iloc[:, :2808], test[2808]], axis=1)\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "\n",
    "# Train only on good\n",
    "X_train = X_train[y_train == 0]\n",
    "X_train_norm = X_train_norm[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 2809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(INPUT_DIM, ))\n",
    "\n",
    "x = Dense(2048, kernel_regularizer=l1_l2(10e-5))(input_layer)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(1024, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(1024, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(2048, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(INPUT_DIM)(x)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adamm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\",\n",
    "                              patience=32,\n",
    "                              verbose=True,\n",
    "                              mode=\"auto\")\n",
    "\n",
    "autoencoder.compile(optimizer=adamm, loss='mean_squared_error')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint((\"%s%s.h5\" % (model_directory, model_name)),\n",
    "                                      monitor=\"val_loss\",\n",
    "                                      verbose=False,\n",
    "                                      save_best_only=True,\n",
    "                                      mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train_norm,\n",
    "                X_train_norm,\n",
    "                epochs=2048,\n",
    "                batch_size=256,\n",
    "                validation_split=0.25,\n",
    "                verbose=2,\n",
    "                callbacks=[early_stopper, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reload saved model\n",
    "autoencoder = load_model(\"%s%s.h5\" % (model_directory, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "ae_pred = autoencoder.predict(X_test_norm)\n",
    "ae_pred_train = autoencoder.predict(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclude validation set\n",
    "ae_pred_train = ae_pred_train[:int(0.75 * len(ae_pred_train)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_pred, open(model_directory + \"ae_pred.p\", \"wb\"))\n",
    "pickle.dump(ae_pred_train, open(model_directory + \"ae_pred_train.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_pred = pickle.load(open(model_directory + \"ae_pred.p\", \"rb\"))\n",
    "ae_pred_train = pickle.load(open(model_directory + \"ae_pred_train.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclude validation set\n",
    "X_train_wo_valid = X_train_norm[:int(0.75 * len(X_train_norm)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_error_df(X_test, predictions, mode=\"allmean\", n_highest = 100):\n",
    "    \n",
    "    if mode == \"allmean\":\n",
    "        return np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "    \n",
    "    elif mode == \"topn\":\n",
    "        temp = np.partition(-np.power(X_test - predictions, 2), n_highest)\n",
    "        result = -temp[:,:n_highest]\n",
    "        return np.mean(result, axis=1)\n",
    "    \n",
    "    elif mode == \"topn_median\":\n",
    "        temp = np.partition(-np.power(X_test - predictions, 2), n_highest)\n",
    "        result = -temp[:,:n_highest]\n",
    "        return np.median(result, axis=1)\n",
    "    \n",
    "    elif mode == \"perobj\":\n",
    "        mses = []\n",
    "        for l in legend:\n",
    "            mse = np.mean(\n",
    "                np.power(X_test[:,l[\"start\"]:l[\"end\"]] - predictions[:,l[\"start\"]:l[\"end\"]], 2),\n",
    "                axis=1)\n",
    "            mses.append(mse)\n",
    "     \n",
    "        return np.maximum.reduce(mses)\n",
    "    \n",
    "    elif mode == \"bottomn\":\n",
    "        temp = np.partition(np.power(X_test - predictions, 2), n_highest)\n",
    "        result = temp[:,:n_highest]\n",
    "        return np.mean(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_error = get_error_df(X_test_norm, ae_pred, mode=\"topn\", n_highest=100)\n",
    "ae_error_train = get_error_df(X_train_wo_valid, ae_pred_train, mode=\"topn\", n_highest=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_error, open(model_directory + \"ae_error.p\", \"wb\"))\n",
    "pickle.dump(ae_error_train, open(model_directory + \"ae_error_train.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot lumi vs error\n",
    "def plot_lumi_error(pred, X_test, threshold=None, title=None):\n",
    "    scores = get_error_df(X_test, pred, mode='topn')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.plot(np.array([i for i in range(len(scores))])[y_test == 0],\n",
    "             scores[y_test == 0],\n",
    "             linestyle='',\n",
    "             ms=2,\n",
    "             marker='o',\n",
    "             label=\"Outlier\")\n",
    "\n",
    "    plt.plot(np.array([i for i in range(len(scores))])[y_test == 1],\n",
    "             scores[y_test == 1],\n",
    "             linestyle='',\n",
    "             ms=2,\n",
    "             marker='o',\n",
    "             label=\"Inlier\")\n",
    "\n",
    "    ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "    \n",
    "    ax.set_yscale(\"log\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Lumisection #\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_legend = 1414\n",
    "var_legend = [{'start': start_legend, 'end': start_legend, 'name': 'mean'},\n",
    "              {'start': start_legend+1, 'end': start_legend+1, 'name': 'RMS'},\n",
    "              {'start': start_legend+2, 'end': start_legend+2, 'name': 'Q1'},\n",
    "              {'start': start_legend+3, 'end': start_legend+3, 'name': 'Q2'},\n",
    "              {'start': start_legend+4, 'end': start_legend+4, 'name': 'Q3'},\n",
    "              {'start': start_legend+5, 'end': start_legend+5, 'name': 'Q4'},\n",
    "              {'start': start_legend+6, 'end': start_legend+6, 'name': 'Q5'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [30, 30]\n",
    "plt_dir = '/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/visualization/plots_train_plots8090/'\n",
    "bins = np.linspace(-50, 50, 50)\n",
    "overlap = []\n",
    "for i in tnrange(X_train.shape[1]):\n",
    "    v, r = divmod(i, 7)\n",
    "    \n",
    "    # Train set\n",
    "    good_input_train = X_train_wo_valid[:, i].reshape(-1)\n",
    "    good_output_train = ae_pred_train[:, i].reshape(-1)\n",
    "    \n",
    "    filter_fraction = 1 # in %\n",
    "    filtered_idx = (good_input_train < np.percentile(good_input_train, 100-filter_fraction))\n",
    "    filtered_idx &= (good_input_train > np.percentile(good_input_train, filter_fraction))\n",
    "    filtered_idx &= (good_output_train < np.percentile(good_output_train, 100-filter_fraction))\n",
    "    filtered_idx &= (good_output_train > np.percentile(good_output_train, filter_fraction))\n",
    "    good_input_filtered_train = good_input_train[filtered_idx]\n",
    "    good_output_filtered_train = good_output_train[filtered_idx]\n",
    "    \n",
    "    good_input_orig = X_train.iloc[:round(0.75*len(X_train)), i].values.reshape(-1)\n",
    "    filtered_orig_idx = (good_input_orig < np.percentile(good_input_orig, 100-filter_fraction))\n",
    "    filtered_orig_idx &= (good_input_orig > np.percentile(good_input_orig, filter_fraction))\n",
    "    good_input_orig_filtered_train = good_input_orig[filtered_orig_idx]\n",
    "    \n",
    "    # Test set\n",
    "    good_input_test = X_test_norm[y_test == 0][:, i].reshape(-1)\n",
    "    good_output_test = ae_pred[y_test == 0][:, i].reshape(-1)\n",
    "    filter_fraction = 1\n",
    "    filtered_idx = (good_input_test < np.percentile(good_input_test, 100-filter_fraction))\n",
    "    filtered_idx &= (good_input_test > np.percentile(good_input_test, filter_fraction))\n",
    "    filtered_idx &= (good_output_test < np.percentile(good_output_test, 100-filter_fraction))\n",
    "    filtered_idx &= (good_output_test > np.percentile(good_output_test, filter_fraction))\n",
    "    good_input_filtered_test = good_input_test[filtered_idx]\n",
    "    good_output_filtered_test = good_output_test[filtered_idx]\n",
    "    \n",
    "    bad_input_test = X_test_norm[y_test == 1][:, i].reshape(-1)\n",
    "    bad_output_test = ae_pred[y_test == 1][:, i].reshape(-1)\n",
    "    filter_fraction = 1\n",
    "    filtered_idx = (bad_input_test < np.percentile(bad_input_test, 100-filter_fraction))\n",
    "    filtered_idx &= (bad_input_test > np.percentile(bad_input_test, filter_fraction))\n",
    "    filtered_idx &= (bad_output_test < np.percentile(bad_output_test, 100-filter_fraction))\n",
    "    filtered_idx &= (bad_output_test > np.percentile(bad_output_test, filter_fraction))\n",
    "    bad_input_filtered_test = bad_input_test[filtered_idx]\n",
    "    bad_output_filtered_test = bad_output_test[filtered_idx]\n",
    "    \n",
    "    good_input_orig = X_test.iloc[:, i][y_test == 0].values.reshape(-1)\n",
    "    filtered_orig_idx = (good_input_orig < np.percentile(good_input_orig, 100-filter_fraction))\n",
    "    filtered_orig_idx &= (good_input_orig > np.percentile(good_input_orig, filter_fraction))\n",
    "    good_input_orig_filtered_test = good_input_orig[filtered_orig_idx]\n",
    "    \n",
    "    bad_input_orig = X_test.iloc[:, i][y_test == 1].values.reshape(-1)\n",
    "    filtered_orig_idx = (bad_input_orig < np.percentile(bad_input_orig, 100-filter_fraction))\n",
    "    filtered_orig_idx &= (bad_input_orig > np.percentile(bad_input_orig, filter_fraction))\n",
    "    bad_input_orig_filtered_test = bad_input_orig[filtered_orig_idx]\n",
    "    \n",
    "#     print(len(good_input_filtered))\n",
    "#     print(len(good_input))\n",
    "#     cut = 100 * (1 - len(good_input_filtered) / len(good_input))\n",
    "#     print(cut)\n",
    "#     overlap_frac = 100 * (4-cut)/2\n",
    "#     print(overlap_frac)\n",
    "#     overlap.append(overlap_frac)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    \n",
    "    axes[(0, 0)].hist(good_input_orig_filtered_train, 100, histtype='step', linewidth=2, label=\"Raw input\")\n",
    "    axes[(0, 0)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' GOOD TRAIN raw input')\n",
    "    axes[(0, 0)].set_xlabel('Values')\n",
    "    axes[(0, 0)].set_ylabel('Number of lumisections')\n",
    "    axes[(0, 0)].legend()\n",
    "    \n",
    "    axes[(0, 1)].hist(good_input_orig_filtered_test, 100, histtype='step', linewidth=2, label=\"Raw input\")\n",
    "    axes[(0, 1)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' GOOD TEST raw input')\n",
    "    axes[(0, 1)].set_xlabel('Values')\n",
    "    axes[(0, 1)].set_ylabel('Number of lumisections')\n",
    "    axes[(0, 1)].legend()\n",
    "    \n",
    "    axes[(0, 2)].hist(bad_input_orig_filtered_test, 100, histtype='step', linewidth=2, label=\"Raw input\")\n",
    "    axes[(0, 2)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' BAD raw input')\n",
    "    axes[(0, 2)].set_xlabel('Values')\n",
    "    axes[(0, 2)].set_ylabel('Number of lumisections')\n",
    "    axes[(0, 2)].legend()\n",
    "    \n",
    "    axes[(1, 0)].hist(good_input_filtered_train, alpha=0.5, histtype='step', linewidth=2, color='b', \n",
    "          label=\"Normalized input\")\n",
    "    axes[(1, 0)].hist(good_output_filtered_train, alpha=0.5, histtype='step', linewidth=2, color='r', \n",
    "          label=\"AE output\")\n",
    "    axes[(1, 0)].set_xlabel('Values')\n",
    "    axes[(1, 0)].set_ylabel('Number of lumisections')\n",
    "    axes[(1, 0)].legend()\n",
    "    axes[(1, 0)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' I/O histogram')\n",
    "    \n",
    "    axes[1][1].hist(good_input_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='b', \n",
    "          label=\"Normalized input\")\n",
    "    axes[1][1].hist(good_output_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='r', \n",
    "          label=\"AE output\")\n",
    "    axes[1][1].set_xlabel('Values')\n",
    "    axes[1][1].set_ylabel('Number of lumisections')\n",
    "    axes[1][1].legend()\n",
    "    axes[1][1].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' I/O histogram')\n",
    "    \n",
    "    axes[1][2].hist(bad_input_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='b', \n",
    "          label=\"Normalized input\")\n",
    "    axes[1][2].hist(bad_output_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='r', \n",
    "          label=\"AE output\")\n",
    "    axes[1][2].set_xlabel('Values')\n",
    "    axes[1][2].set_ylabel('Number of lumisections')\n",
    "    axes[1][2].legend()\n",
    "    axes[1][2].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' I/O histogram')\n",
    "    \n",
    "    axes[2][0].hist2d(good_input_filtered_train, good_output_filtered_train, norm=LogNorm(),\n",
    "                      bins=200)\n",
    "    axes[2][0].set_title('corr. coeff.:' \n",
    "                         + str(round(pearsonr(good_input_train, good_output_train)[0], 2)))\n",
    "    axes[2][0].set_xlabel('Input values')\n",
    "    axes[2][0].set_ylabel('Output values')\n",
    "    axes[2][0].axis('equal')\n",
    "    \n",
    "    axes[2][1].hist2d(good_input_filtered_test, good_output_filtered_test, norm=LogNorm(),\n",
    "                      bins=200)\n",
    "    axes[2][1].set_title('corr. coeff.:' \n",
    "                         + str(round(pearsonr(good_input_test, good_output_test)[0], 2)))\n",
    "    axes[2][1].set_xlabel('Input values')\n",
    "    axes[2][1].set_ylabel('Output values')\n",
    "    axes[2][1].axis('equal')\n",
    "    \n",
    "    axes[2][2].hist2d(bad_input_filtered_test, bad_output_filtered_test, norm=LogNorm(), \n",
    "                      bins=200)\n",
    "    axes[2][2].set_title('corr. coeff.:' \n",
    "                         + str(round(pearsonr(bad_input_test, bad_output_test)[0], 2)))\n",
    "    axes[2][2].set_xlabel('Input values')\n",
    "    axes[2][2].set_ylabel('Output values')\n",
    "    axes[2][2].axis('equal')\n",
    "    \n",
    "#     plt.savefig(plt_dir + str(i) + '_' + feature_names[v] + '_' + var_legend[r]['name'])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('####################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = [pearsonr(X_train_wo_valid[:, i].reshape(-1), ae_pred_train[:, i].reshape(-1)) for i in range(INPUT_DIM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = np.array(corr)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr[np.isnan(corr)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(corr, bins=100)\n",
    "plt.title('Histogram of correlation coefficients for 2809 features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_filter = corr > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variance = np.var(data.iloc[:, 0:INPUT_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_filter = variance != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_filter = corr_filter & var_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_filtered = X_train_norm[:, feature_filter]\n",
    "X_train_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_filtered_wo_valid = X_train.iloc[:round(0.75*len(X_train)), :]\n",
    "X_train_filtered_wo_valid = np.array(X_train_filtered_wo_valid)[:, feature_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_dim = X_train_filtered.shape[1]\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "x = Dense(1024, kernel_regularizer=l1_l2(10e-5))(input_layer)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(32, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(64, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(128, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(1024, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = Dense(input_dim)(x)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name2 = 'ae2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adamm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\",\n",
    "                              patience=32,\n",
    "                              verbose=True,\n",
    "                              mode=\"auto\")\n",
    "\n",
    "autoencoder.compile(optimizer=adamm, loss='mean_squared_error')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint((\"%s%s.h5\" % (model_directory, model_name2)),\n",
    "                                      monitor=\"val_loss\",\n",
    "                                      verbose=False,\n",
    "                                      save_best_only=True,\n",
    "                                      mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train_filtered,\n",
    "                X_train_filtered,\n",
    "                epochs=2048,\n",
    "                batch_size=256,\n",
    "                validation_split=0.25,\n",
    "                verbose=2,\n",
    "                callbacks=[early_stopper, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reload saved model\n",
    "autoencoder = load_model(\"%s%s.h5\" % (model_directory, model_name2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_filtered = X_test_norm[:, feature_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exclude validation set\n",
    "X_train_wo_valid_filtered = X_train_wo_valid[:, feature_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "ae_pred_filtered = autoencoder.predict(X_test_filtered)\n",
    "ae_pred_filtered_train = autoencoder.predict(X_train_wo_valid_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_pred_filtered, open(model_directory + \"ae_pred_filtered.p\", \"wb\"))\n",
    "pickle.dump(ae_pred_filtered_train, open(model_directory + \"ae_pred_filtered_train.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_pred_filtered = pickle.load(open(model_directory + \"ae_pred_filtered.p\", \"rb\"))\n",
    "ae_pred_filtered_train = pickle.load(open(model_directory + \"ae_pred_filtered_train.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_error_filtered = get_error_df(X_test_filtered, ae_pred_filtered, mode=\"topn\", n_highest=100)\n",
    "ae_error_filtered_train = get_error_df(X_train_wo_valid_filtered, ae_pred_filtered_train, mode=\"topn\", n_highest=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_error_filtered, open(model_directory + \"ae_error_filtered.p\", \"wb\"))\n",
    "pickle.dump(ae_error_filtered_train, open(model_directory + \"ae_error_filtered_train.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [30, 30]\n",
    "plt_dir = '/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/visualization/plots_train_reduced_features/'\n",
    "bins = np.linspace(-50, 50, 50)\n",
    "overlap = []\n",
    "for i in tnrange(X_test_filtered.shape[1]):\n",
    "    v, r = divmod(i, 7)\n",
    "    \n",
    "    # Train set\n",
    "    good_input_train = X_train_wo_valid_filtered[:, i].reshape(-1)\n",
    "    good_output_train = ae_pred_filtered_train[:, i].reshape(-1)\n",
    "    filter_fraction = 1 # in %\n",
    "    filtered_idx = (good_input_train < np.percentile(good_input_train, 100-filter_fraction))\n",
    "    filtered_idx &= (good_input_train > np.percentile(good_input_train, filter_fraction))\n",
    "    filtered_idx &= (good_output_train < np.percentile(good_output_train, 100-filter_fraction))\n",
    "    filtered_idx &= (good_output_train > np.percentile(good_output_train, filter_fraction))\n",
    "    good_input_filtered_train = good_input_train[filtered_idx]\n",
    "    good_output_filtered_train = good_output_train[filtered_idx]\n",
    "    \n",
    "    good_input_orig = X_train_filtered_wo_valid[:, i].reshape(-1)\n",
    "    filtered_orig_idx = (good_input_orig < np.percentile(good_input_orig, 100-filter_fraction))\n",
    "    filtered_orig_idx &= (good_input_orig > np.percentile(good_input_orig, filter_fraction))\n",
    "    good_input_orig_filtered_train = good_input_orig[filtered_orig_idx]\n",
    "    \n",
    "    # Test set\n",
    "    good_input_test = X_test_filtered[y_test == 0][:, i].reshape(-1)\n",
    "    good_output_test = ae_pred_filtered[y_test == 0][:, i].reshape(-1)\n",
    "    filter_fraction = 1\n",
    "    filtered_idx = (good_input_test < np.percentile(good_input_test, 100-filter_fraction))\n",
    "    filtered_idx &= (good_input_test > np.percentile(good_input_test, filter_fraction))\n",
    "    filtered_idx &= (good_output_test < np.percentile(good_output_test, 100-filter_fraction))\n",
    "    filtered_idx &= (good_output_test > np.percentile(good_output_test, filter_fraction))\n",
    "    good_input_filtered_test = good_input_test[filtered_idx]\n",
    "    good_output_filtered_test = good_output_test[filtered_idx]\n",
    "    \n",
    "    bad_input_test = X_test_filtered[y_test == 1][:, i].reshape(-1)\n",
    "    bad_output_test = ae_pred_filtered[y_test == 1][:, i].reshape(-1)\n",
    "    filter_fraction = 1\n",
    "    filtered_idx = (bad_input_test < np.percentile(bad_input_test, 100-filter_fraction))\n",
    "    filtered_idx &= (bad_input_test > np.percentile(bad_input_test, filter_fraction))\n",
    "    filtered_idx &= (bad_output_test < np.percentile(bad_output_test, 100-filter_fraction))\n",
    "    filtered_idx &= (bad_output_test > np.percentile(bad_output_test, filter_fraction))\n",
    "    bad_input_filtered_test = bad_input_test[filtered_idx]\n",
    "    bad_output_filtered_test = bad_output_test[filtered_idx]\n",
    "    \n",
    "    good_input_orig = X_test_filtered[:, i][y_test == 0].reshape(-1)\n",
    "    filtered_orig_idx = (good_input_orig < np.percentile(good_input_orig, 100-filter_fraction))\n",
    "    filtered_orig_idx &= (good_input_orig > np.percentile(good_input_orig, filter_fraction))\n",
    "    good_input_orig_filtered_test = good_input_orig[filtered_orig_idx]\n",
    "    \n",
    "    bad_input_orig = X_test_filtered[:, i][y_test == 1].reshape(-1)\n",
    "    filtered_orig_idx = (bad_input_orig < np.percentile(bad_input_orig, 100-filter_fraction))\n",
    "    filtered_orig_idx &= (bad_input_orig > np.percentile(bad_input_orig, filter_fraction))\n",
    "    bad_input_orig_filtered_test = bad_input_orig[filtered_orig_idx]\n",
    "    \n",
    "#     print(len(good_input_filtered))\n",
    "#     print(len(good_input))\n",
    "#     cut = 100 * (1 - len(good_input_filtered) / len(good_input))\n",
    "#     print(cut)\n",
    "#     overlap_frac = 100 * (4-cut)/2\n",
    "#     print(overlap_frac)\n",
    "#     overlap.append(overlap_frac)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    \n",
    "    axes[(0, 0)].hist(good_input_orig_filtered_train, 100, histtype='step', linewidth=2, label=\"Raw input\")\n",
    "    axes[(0, 0)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' GOOD TRAIN raw input')\n",
    "    axes[(0, 0)].set_xlabel('Values')\n",
    "    axes[(0, 0)].set_ylabel('Number of lumisections')\n",
    "    axes[(0, 0)].legend()\n",
    "    \n",
    "    axes[(0, 1)].hist(good_input_orig_filtered_test, 100, histtype='step', linewidth=2, label=\"Raw input\")\n",
    "    axes[(0, 1)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' GOOD TEST raw input')\n",
    "    axes[(0, 1)].set_xlabel('Values')\n",
    "    axes[(0, 1)].set_ylabel('Number of lumisections')\n",
    "    axes[(0, 1)].legend()\n",
    "    \n",
    "    axes[(0, 2)].hist(bad_input_orig_filtered_test, 100, histtype='step', linewidth=2, label=\"Raw input\")\n",
    "    axes[(0, 2)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' BAD raw input')\n",
    "    axes[(0, 2)].set_xlabel('Values')\n",
    "    axes[(0, 2)].set_ylabel('Number of lumisections')\n",
    "    axes[(0, 2)].legend()\n",
    "    \n",
    "    axes[(1, 0)].hist(good_input_filtered_train, alpha=0.5, histtype='step', linewidth=2, color='b', \n",
    "          label=\"Normalized input\")\n",
    "    axes[(1, 0)].hist(good_output_filtered_train, alpha=0.5, histtype='step', linewidth=2, color='r', \n",
    "          label=\"AE output\")\n",
    "    axes[(1, 0)].set_xlabel('Values')\n",
    "    axes[(1, 0)].set_ylabel('Number of lumisections')\n",
    "    axes[(1, 0)].legend()\n",
    "    axes[(1, 0)].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' I/O histogram')\n",
    "    \n",
    "    axes[1][1].hist(good_input_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='b', \n",
    "          label=\"Normalized input\")\n",
    "    axes[1][1].hist(good_output_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='r', \n",
    "          label=\"AE output\")\n",
    "    axes[1][1].set_xlabel('Values')\n",
    "    axes[1][1].set_ylabel('Number of lumisections')\n",
    "    axes[1][1].legend()\n",
    "    axes[1][1].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' I/O histogram')\n",
    "    \n",
    "    axes[1][2].hist(bad_input_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='b', \n",
    "          label=\"Normalized input\")\n",
    "    axes[1][2].hist(bad_output_filtered_test, alpha=0.5, histtype='step', linewidth=2, color='r', \n",
    "          label=\"AE output\")\n",
    "    axes[1][2].set_xlabel('Values')\n",
    "    axes[1][2].set_ylabel('Number of lumisections')\n",
    "    axes[1][2].legend()\n",
    "    axes[1][2].set_title(feature_names[v] + ' ' + var_legend[r]['name'] + ' I/O histogram')\n",
    "    \n",
    "    axes[2][0].hist2d(good_input_filtered_train, good_output_filtered_train, norm=LogNorm(),\n",
    "                      bins=200)\n",
    "    axes[2][0].set_title('corr. coeff.:' \n",
    "                         + str(round(pearsonr(good_input_train, good_output_train)[0], 2)))\n",
    "    axes[2][0].set_xlabel('Input values')\n",
    "    axes[2][0].set_ylabel('Output values')\n",
    "    axes[2][0].axis('equal')\n",
    "    \n",
    "    axes[2][1].hist2d(good_input_filtered_test, good_output_filtered_test, norm=LogNorm(),\n",
    "                      bins=200)\n",
    "    axes[2][1].set_title('corr. coeff.:' \n",
    "                         + str(round(pearsonr(good_input_test, good_output_test)[0], 2)))\n",
    "    axes[2][1].set_xlabel('Input values')\n",
    "    axes[2][1].set_ylabel('Output values')\n",
    "    axes[2][1].axis('equal')\n",
    "    \n",
    "    axes[2][2].hist2d(bad_input_filtered_test, bad_output_filtered_test, norm=LogNorm(), \n",
    "                      bins=200)\n",
    "    axes[2][2].set_title('corr. coeff.:' \n",
    "                         + str(round(pearsonr(bad_input_test, bad_output_test)[0], 2)))\n",
    "    axes[2][2].set_xlabel('Input values')\n",
    "    axes[2][2].set_ylabel('Output values')\n",
    "    axes[2][2].axis('equal')\n",
    "    \n",
    "#     plt.savefig(plt_dir + str(i) + '_' + feature_names[v] + '_' + var_legend[r]['name'])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('####################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plot_lumi_error(np.zeros(ae_pred.shape), X_test_norm, title='Mean square score across lumisections')\n",
    "plot_lumi_error(ae_pred, X_test_norm, title='AE reco errror across lumisections')\n",
    "plot_lumi_error(ae_pred_filtered, X_test_filtered, \n",
    "                title='AE filtered reco errror across lumisections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make ROC_curve\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score                          \n",
    "\n",
    "def get_roc_curve(label, pred, X_tests, names):\n",
    "    \"\"\"Generates ROC Curves for a given array\"\"\"\n",
    "    scores = [get_error_df(X_tests[i], pred[i], mode='topn') for i in range(len(pred))]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        fpr, tpr, thresholds = roc_curve(label, scores[i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr,\n",
    "                 tpr,\n",
    "                 linewidth=3,\n",
    "                 label=(\"%s AUC: %s\" % (names[i], roc_auc)))\n",
    "        \n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylabel(\"Sensitivity (TPR)\")\n",
    "    plt.xlabel(\"Fall-out (TNR)\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlim([0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "get_roc_curve(y_test, [ae_pred, ae_pred_filtered, np.zeros(ae_pred.shape)],\n",
    "              [X_test_norm, X_test_filtered, X_test_norm], ['AE', 'AE filtered', 'Mean square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "LABELS = [\"Normal\", \"Anomalous\"]\n",
    "\n",
    "def conf_matrix(scores, y_true, threshold, title):\n",
    "    y_pred = [1 if e > threshold else 0 for e in scores]\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    class_imbal = np.mean(1 - y_true)\n",
    "    adj_acc = (acc - class_imbal) / (1 - class_imbal)\n",
    "\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print(\"Adjusted accuracy:\", adj_acc)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conf_matrix(ae_error_filtered, y_test, 1.5e0, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_vs_feature(y_val, x_val, y_class, y_name=\"\", x_name=\"\", selected=[], linear=False,\n",
    "                    limit=False):\n",
    "    '''\n",
    "    Plots two arbitrary values agains each other.\n",
    "    '''\n",
    "    df = pd.DataFrame({'y_val': y_val,\n",
    "                       'x_val': x_val,\n",
    "                       'y_class': y_class})\n",
    "\n",
    "    groups = df.groupby('y_class')\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x_val, \n",
    "                group.y_val,\n",
    "                color=\"red\" if name == 1 else \"blue\",\n",
    "                marker='o',\n",
    "                ms=2,\n",
    "                linestyle='',\n",
    "                label= \"Anomaly\" if name == 1 else \"Normal\")\n",
    "\n",
    "    for i in selected:\n",
    "        ax.plot(x_val[i],\n",
    "                y_val[i],\n",
    "                color=\"green\",\n",
    "                marker='o',\n",
    "                ms=4,\n",
    "                linestyle='')\n",
    "                 \n",
    "    ax.legend()\n",
    "    if not linear:\n",
    "        ax.set_yscale('log')\n",
    "    if limit:\n",
    "        plt.xlim([limit[0], limit[1]])\n",
    "    plt.grid()\n",
    "    plt.ylabel(y_name)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "pred_vs_feature(ae_error, X_test[2807], y_test, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "pred_vs_feature(ae_error_filtered, X_test[2807], y_test, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_directory_np_b = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_bottleneck/\"\n",
    "model_directory_p_b = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_w_pileup/\"\n",
    "model_directory_p_nb = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_w_pileup_no_bottleneck/\"\n",
    "model_directory_np_nb = \"/eos/user/t/tkrzyzek/autoencoder/plots_train_no_pileup_no_bottleneck/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_b_ae_error = pickle.load(open(model_directory_np_b + \"ae_error.p\", \"rb\"))\n",
    "np_b_ae_error_filtered = pickle.load(open(model_directory_np_b + \"ae_error_filtered.p\", \"rb\"))\n",
    "\n",
    "p_b_ae_error = pickle.load(open(model_directory_p_b + \"ae_error.p\", \"rb\"))\n",
    "p_b_ae_error_filtered = pickle.load(open(model_directory_p_b + \"ae_error_filtered.p\", \"rb\"))\n",
    "\n",
    "\n",
    "p_nb_ae_error = pickle.load(open(model_directory_p_nb + \"ae_error.p\", \"rb\"))\n",
    "p_nb_ae_error_filtered = pickle.load(open(model_directory_p_nb + \"ae_error_filtered.p\", \"rb\"))\n",
    "\n",
    "\n",
    "np_nb_ae_error = pickle.load(open(model_directory_np_nb + \"ae_error.p\", \"rb\"))\n",
    "np_nb_ae_error_filtered = pickle.load(open(model_directory_np_nb + \"ae_error_filtered.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_vs_feature4(y_vals, x_val, y_class, y_name=\"\", x_name=\"\", linear=False, \n",
    "                     limit=False):\n",
    "    '''\n",
    "    Plots two arbitrary values agains each other.\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    \n",
    "    for i in range(4):\n",
    "        df = pd.DataFrame({'y_val': y_vals[i],\n",
    "                           'x_val': x_val,\n",
    "                           'y_class': y_class})\n",
    "\n",
    "        groups = df.groupby('y_class')\n",
    "        if i < 2:\n",
    "            ax = axes[0, i%2]\n",
    "        else:\n",
    "            ax = axes[1, i%2]\n",
    "        \n",
    "        for name, group in groups:\n",
    "            ax.plot(group.x_val, \n",
    "                    group.y_val,\n",
    "                    color=\"red\" if name == 1 else \"blue\",\n",
    "                    marker='o',\n",
    "                    ms=2,\n",
    "                    linestyle='',\n",
    "                    label= \"Anomaly\" if name == 1 else \"Normal\")\n",
    "\n",
    "        ax.legend()\n",
    "        if not linear:\n",
    "            ax.set_yscale('log')\n",
    "        if limit:\n",
    "            plt.xlim([limit[0], limit[1]])\n",
    "        ax.set_ylabel(y_name)\n",
    "        ax.set_xlabel(x_name)\n",
    "        plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "pred_vs_feature4([np_b_ae_error, p_b_ae_error, p_nb_ae_error, np_nb_ae_error],\n",
    "                X_test[2807], y_test, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "pred_vs_feature4([np_b_ae_error_filtered, p_b_ae_error_filtered, p_nb_ae_error_filtered,\n",
    "                  np_nb_ae_error_filtered], X_test[2807], y_test, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "pred_vs_feature4([np_b_ae_error, p_b_ae_error, p_nb_ae_error, np_nb_ae_error],\n",
    "                X_test[2808], y_test, \"AE reco error\", \"Pileup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "pred_vs_feature4([np_b_ae_error_filtered, p_b_ae_error_filtered, p_nb_ae_error_filtered,\n",
    "                  np_nb_ae_error_filtered], X_test[2808], y_test, \"AE reco error\", \"Pileup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
