{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "# Running on GPU?\n",
    "import setGPU\n",
    "\n",
    "import getpass\n",
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-229fcbeab4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get permission to access EOS (Insert your NICE password)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"echo %s | kinit\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get permission to access EOS (Insert your NICE password)\n",
    "os.system(\"echo %s | kinit\" % getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input, Dense, Lambda, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.activations import sigmoid, linear, relu\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PDs  = {1: 'BTagCSV',\n",
    "        2: 'BTagMu',\n",
    "        3: 'Charmonium',\n",
    "        4: 'DisplacedJet',\n",
    "        5: 'DoubleEG',\n",
    "        6: 'DoubleMuon',\n",
    "        7: 'DoubleMuonLowMass',\n",
    "        8: 'FSQJets',\n",
    "        9: 'HighMultiplicityEOF',\n",
    "        10: 'HTMHT',\n",
    "        11: 'JetHT',\n",
    "        12: 'MET',\n",
    "        13: 'MinimumBias',\n",
    "        14: 'MuonEG',\n",
    "        15: 'MuOnia',\n",
    "        16: 'NoBPTX',\n",
    "        17: 'SingleElectron',\n",
    "        18: 'SingleMuon',\n",
    "        19: 'SinglePhoton',\n",
    "        20: 'Tau',\n",
    "        21: 'ZeroBias'}\n",
    "\n",
    "# Select PD\n",
    "nPD = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = \"/eos/cms/store/user/fsiroky/consistentlumih5/\"\n",
    "label_file = \"/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/JetHT.json\"\n",
    "model_directory = \"/eos/user/t/tkrzyzek/autoencoder/batch_norm/\"\n",
    "model_name = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(directory, pds, npd, typeof, extension):\n",
    "    files = []\n",
    "    parts = [\"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "    for p in parts:\n",
    "        files.append(\"%s%s_%s_%s%s\" % (directory, pds[npd], p, typeof, extension))\n",
    "    return files\n",
    "\n",
    "files = get_file_list(data_directory, PDs, nPD, \"background\", \".h5\")\n",
    "files = files + get_file_list(data_directory, PDs, nPD, \"signal\", \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load good and bad jets\n",
    "def get_data(files):\n",
    "    readout = np.empty([0,2813])\n",
    "    \n",
    "    for file in files:\n",
    "        jet = file.split(\"/\")[-1][:-3]\n",
    "        print(\"Reading: %s\" % jet)\n",
    "        try:\n",
    "            h5file = h5py.File(file, \"r\")\n",
    "            readout = np.concatenate((readout, h5file[jet][:]), axis=0)\n",
    "        except OSError as error:\n",
    "            print(\"This Primary Dataset doesn't have %s. %s\" % (jet, error))\n",
    "            continue\n",
    "\n",
    "    return readout\n",
    "\n",
    "data = pd.DataFrame(get_data(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"run\"] = data[2807].astype(int)\n",
    "data[\"lumi\"] = data[2808].astype(int)\n",
    "data[\"inst_lumi\"] = data[2809].astype(float)\n",
    "\n",
    "# Drop unnecessary meta data\n",
    "data.drop([2807, 2808, 2809, 2810, 2811, 2812], axis=1, inplace=True)\n",
    "\n",
    "# Sort by runID and then by lumiID\n",
    "data = data.sort_values([\"run\", \"lumi\"], ascending=[True,True])\n",
    "\n",
    "# Reset index\n",
    "data = data.reset_index(drop=True)  \n",
    "\n",
    "runIDs  = data[\"run\"].astype(int)\n",
    "lumiIDs = data[\"lumi\"].astype(int)\n",
    "luminosity = data[\"inst_lumi\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply labels\n",
    "output_json = json.load(open(label_file))\n",
    "\n",
    "def json_checker(json_file, orig_runid, orig_lumid):\n",
    "    try:\n",
    "        for i in json_file[str(int(orig_runid))]:\n",
    "            if orig_lumid >= i[0] and orig_lumid <= i[1]:\n",
    "                return 0\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "def add_flags(sample):\n",
    "    return json_checker(output_json, sample[\"run\"], sample[\"lumi\"])\n",
    "\n",
    "data[\"label\"] = data.apply(add_flags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# treshold = 4e7\n",
    "# plt.rcParams['figure.figsize'] = [40, 20]\n",
    "# plt.hist(data.iloc[:, :2807].values.reshape(-1), bins=1000)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.axvline(treshold, color='r')\n",
    "# plt.ylabel(\"Feature value\")\n",
    "# plt.xlabel(\"Number of feature values\")\n",
    "# plt.title(\"Histogram of all feature values of all lumisections\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data['keep'] = data.apply(lambda row: all([x < treshold for x in row]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data[data['keep'] == False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_orig = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (16368, 2811)\n",
      "After: (16368, 2811)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "SPLIT_FACTOR = 0.1\n",
    "\n",
    "split = round(SPLIT_FACTOR*len(data))\n",
    "\n",
    "runIDs = runIDs[split:]\n",
    "lumiIDs = lumiIDs[split:]\n",
    "luminosity = luminosity[split:]\n",
    "\n",
    "train = data.iloc[:split]\n",
    "print(\"Before:\", train.shape)\n",
    "# train = train[train['keep'] == True]\n",
    "print(\"After:\", train.shape)\n",
    "X_train = train.iloc[:, 0:2806]\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "test = data.iloc[split:]\n",
    "X_test = test.iloc[:, 0:2806]\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "\n",
    "# Train only on good\n",
    "X_train = X_train[y_train == 0]\n",
    "X_train_norm = X_train_norm[y_train == 0]\n",
    "\n",
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2806)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2806)              11224     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2000)              5614000   \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, 2000)              2000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2000)              8000      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "p_re_lu_7 (PReLU)            (None, 1000)              1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "p_re_lu_8 (PReLU)            (None, 500)               500       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "p_re_lu_9 (PReLU)            (None, 1000)              1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2000)              2002000   \n",
      "_________________________________________________________________\n",
      "p_re_lu_10 (PReLU)           (None, 2000)              2000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 2000)              8000      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2806)              5614806   \n",
      "=================================================================\n",
      "Total params: 16,277,030\n",
      "Trainable params: 16,258,418\n",
      "Non-trainable params: 18,612\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "x = BatchNormalization()(input_layer)\n",
    "x = Dense(2000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(500, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(2000, kernel_regularizer=l1_l2(10e-5))(x)\n",
    "x = PReLU()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(input_dim)(x)\n",
    "x = linear(x)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 2806)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2806)              11224     \n",
      "=================================================================\n",
      "Total params: 11,224\n",
      "Trainable params: 5,612\n",
      "Non-trainable params: 5,612\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "x = BatchNormalization()(input_layer)\n",
    "\n",
    "norm_model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "norm_model.summary()\n",
    "\n",
    "adamm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "norm_model.compile(optimizer=adamm, loss='mean_squared_error')\n",
    "\n",
    "X_train_minibatch_norm = norm_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adamm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\",\n",
    "                              patience=32,\n",
    "                              verbose=True,\n",
    "                              mode=\"auto\")\n",
    "\n",
    "autoencoder.compile(optimizer=adamm, loss='mean_squared_error')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint((\"%s%s.h5\" % (model_directory, model_name)),\n",
    "                                      monitor=\"val_loss\",\n",
    "                                      verbose=False,\n",
    "                                      save_best_only=True,\n",
    "                                      mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11859 samples, validate on 3954 samples\n",
      "Epoch 1/64\n",
      "41s - loss: 3435161384.5134 - val_loss: 443383402.8366\n",
      "Epoch 2/64\n",
      "27s - loss: 3435149664.3211 - val_loss: 443377041.0197\n",
      "Epoch 3/64\n",
      "31s - loss: 3435141703.7582 - val_loss: 443369328.0567\n",
      "Epoch 4/64\n",
      "37s - loss: 3435136843.1394 - val_loss: 443362455.9150\n",
      "Epoch 5/64\n",
      "30s - loss: 3435132248.7333 - val_loss: 443356242.5979\n",
      "Epoch 6/64\n",
      "29s - loss: 3435122420.5656 - val_loss: 443355990.9277\n",
      "Epoch 7/64\n",
      "2s - loss: 3435116005.0809 - val_loss: 443357456.9631\n",
      "Epoch 8/64\n",
      "2s - loss: 3435104281.7863 - val_loss: 443359880.0931\n",
      "Epoch 9/64\n",
      "2s - loss: 3435091054.4866 - val_loss: 443368030.0253\n",
      "Epoch 10/64\n",
      "2s - loss: 3435083410.3058 - val_loss: 443368391.0086\n",
      "Epoch 11/64\n",
      "2s - loss: 3435072814.2663 - val_loss: 443368279.2514\n",
      "Epoch 12/64\n",
      "2s - loss: 3435064270.7854 - val_loss: 443363350.1345\n",
      "Epoch 13/64\n",
      "2s - loss: 3435050981.7562 - val_loss: 443356809.4284\n",
      "Epoch 14/64\n",
      "28s - loss: 3435039983.1922 - val_loss: 443354669.1512\n",
      "Epoch 15/64\n",
      "32s - loss: 3435035870.9126 - val_loss: 443345958.2479\n",
      "Epoch 16/64\n",
      "17s - loss: 3435025339.3473 - val_loss: 443332106.8204\n",
      "Epoch 17/64\n",
      "2s - loss: 3435013561.7114 - val_loss: 443339233.9666\n",
      "Epoch 18/64\n",
      "35s - loss: 3434994639.2536 - val_loss: 443327449.1533\n",
      "Epoch 19/64\n",
      "28s - loss: 3434992307.6573 - val_loss: 443316625.8857\n",
      "Epoch 20/64\n",
      "27s - loss: 3435001262.5968 - val_loss: 443313970.9944\n",
      "Epoch 21/64\n",
      "25s - loss: 3434969478.3142 - val_loss: 443306774.6525\n",
      "Epoch 22/64\n",
      "31s - loss: 3434972093.2854 - val_loss: 443289082.1406\n",
      "Epoch 23/64\n",
      "2s - loss: 3434952168.6969 - val_loss: 443294026.2944\n",
      "Epoch 24/64\n",
      "27s - loss: 3434947389.6214 - val_loss: 443271290.7800\n",
      "Epoch 25/64\n",
      "34s - loss: 3434936096.5813 - val_loss: 443254520.4249\n",
      "Epoch 26/64\n",
      "34s - loss: 3434912981.9012 - val_loss: 443253333.7865\n",
      "Epoch 27/64\n",
      "32s - loss: 3434931658.1725 - val_loss: 443235798.3369\n",
      "Epoch 28/64\n",
      "39s - loss: 3434914085.2483 - val_loss: 443212780.8599\n",
      "Epoch 29/64\n",
      "18s - loss: 3434893193.5307 - val_loss: 443208618.9580\n",
      "Epoch 30/64\n",
      "35s - loss: 3434880644.4242 - val_loss: 443196689.5781\n",
      "Epoch 31/64\n",
      "2s - loss: 3434866554.9399 - val_loss: 443223667.2210\n",
      "Epoch 32/64\n",
      "2s - loss: 3434854928.9728 - val_loss: 443227767.7936\n",
      "Epoch 33/64\n",
      "2s - loss: 3434854057.7627 - val_loss: 443220781.5721\n",
      "Epoch 34/64\n",
      "9s - loss: 3434842833.5556 - val_loss: 443192466.9297\n",
      "Epoch 35/64\n",
      "2s - loss: 3434829654.1830 - val_loss: 443195065.7602\n",
      "Epoch 36/64\n",
      "13s - loss: 3434835917.5485 - val_loss: 443176895.0612\n",
      "Epoch 37/64\n",
      "27s - loss: 3434805068.2945 - val_loss: 443176746.6909\n",
      "Epoch 38/64\n",
      "15s - loss: 3434796713.9371 - val_loss: 443156229.6571\n",
      "Epoch 39/64\n",
      "2s - loss: 3434786179.1436 - val_loss: 443163522.0314\n",
      "Epoch 40/64\n",
      "27s - loss: 3434791419.3989 - val_loss: 443152031.5225\n",
      "Epoch 41/64\n",
      "4s - loss: 3434792133.6376 - val_loss: 443133598.6646\n",
      "Epoch 42/64\n",
      "2s - loss: 3434758973.8207 - val_loss: 443146662.4340\n",
      "Epoch 43/64\n",
      "2s - loss: 3434752804.8911 - val_loss: 443138995.7957\n",
      "Epoch 44/64\n",
      "2s - loss: 3434746611.3915 - val_loss: 443150059.7592\n",
      "Epoch 45/64\n",
      "2s - loss: 3434723770.7432 - val_loss: 443150560.3723\n",
      "Epoch 46/64\n",
      "2s - loss: 3434720519.4765 - val_loss: 443149410.7921\n",
      "Epoch 47/64\n",
      "4s - loss: 3434723793.8153 - val_loss: 443118306.3389\n",
      "Epoch 48/64\n",
      "26s - loss: 3434706198.9578 - val_loss: 443116434.7436\n",
      "Epoch 49/64\n",
      "2s - loss: 3434697119.5467 - val_loss: 443126823.5589\n",
      "Epoch 50/64\n",
      "37s - loss: 3434691639.8475 - val_loss: 443115860.7183\n",
      "Epoch 51/64\n",
      "19s - loss: 3434681963.6401 - val_loss: 443104514.4603\n",
      "Epoch 52/64\n",
      "17s - loss: 3434659139.9619 - val_loss: 443086519.6641\n",
      "Epoch 53/64\n",
      "2s - loss: 3434671268.0309 - val_loss: 443104964.8801\n",
      "Epoch 54/64\n",
      "2s - loss: 3434639110.6083 - val_loss: 443090056.2468\n",
      "Epoch 55/64\n",
      "22s - loss: 3434646536.0806 - val_loss: 443064451.2291\n",
      "Epoch 56/64\n",
      "17s - loss: 3434658315.3817 - val_loss: 443023540.6697\n",
      "Epoch 57/64\n",
      "2s - loss: 3434620998.3439 - val_loss: 443058542.9965\n",
      "Epoch 58/64\n",
      "2s - loss: 3434604044.6287 - val_loss: 443052634.5210\n",
      "Epoch 59/64\n",
      "2s - loss: 3434604751.6775 - val_loss: 443068796.3257\n",
      "Epoch 60/64\n",
      "2s - loss: 3434564044.6877 - val_loss: 443098863.5549\n",
      "Epoch 61/64\n",
      "2s - loss: 3434607636.1155 - val_loss: 443097686.2236\n",
      "Epoch 62/64\n",
      "2s - loss: 3434567909.4172 - val_loss: 443077137.2382\n",
      "Epoch 63/64\n",
      "2s - loss: 3434529887.0421 - val_loss: 443094371.0673\n",
      "Epoch 64/64\n",
      "2s - loss: 3434538182.8950 - val_loss: 443086303.8139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2544399f60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train,\n",
    "                X_train_minibatch_norm,\n",
    "                epochs=64,\n",
    "                batch_size=256,\n",
    "                validation_split=0.25,\n",
    "                verbose=2,\n",
    "                callbacks=[early_stopper, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reload saved model\n",
    "autoencoder = load_model(\"%s%s.h5\" % (model_directory, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "predictions = autoencoder.predict(X_test)\n",
    "\n",
    "def get_error_df(X_test, predictions, mode=\"allmean\", n_highest = 100):\n",
    "    \n",
    "    if mode == \"allmean\":\n",
    "        return np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "    \n",
    "    elif mode == \"topn\":\n",
    "        temp = np.partition(-np.power(X_test - predictions, 2), n_highest)\n",
    "        result = -temp[:,:n_highest]\n",
    "        return np.mean(result, axis=1)\n",
    "    \n",
    "    elif mode == \"perobj\":\n",
    "        mses = []\n",
    "        for l in legend:\n",
    "            mse = np.mean(\n",
    "                np.power(X_test[:,l[\"start\"]:l[\"end\"]] - predictions[:,l[\"start\"]:l[\"end\"]], 2),\n",
    "                axis=1)\n",
    "            mses.append(mse)\n",
    "     \n",
    "        return np.maximum.reduce(mses)\n",
    "    \n",
    "ae_error = get_error_df(X_test, predictions, mode=\"topn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxidLFMYYY3yyRGGMMcan/wenYMDX8slsUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f216c01cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make ROC_curve\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score                          \n",
    "\n",
    "def get_roc_curve(label, scores, names):\n",
    "    \"\"\"Generates ROC Curves for a given array\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        fpr, tpr, thresholds = roc_curve(label, scores[i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr,\n",
    "                 tpr,\n",
    "                 linewidth=3,\n",
    "                 #linestyle=line_styles[0],\n",
    "                 label=(\"%s AUC: %s\" % (names[i], roc_auc)))\n",
    "        \n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylabel(\"Sensitivity (TPR)\")\n",
    "    plt.xlabel(\"Fall-out (TNR)\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlim([0, 1])\n",
    "    plt.title('ROC curves for AE with batchnorm')\n",
    "    plt.show();\n",
    "    \n",
    "get_roc_curve(y_test, [ae_error], ['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_directory = \"/afs/cern.ch/user/t/tkrzyzek/Documents/Data-Certification/temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(ae_error, open(model_directory + \"ae_error.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
