{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Luminosity dependency of reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get permission to access EOS (Insert your NICE password)\n",
    "\n",
    "os.system(\"echo %s | kinit\" % getpass.getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make ROC_curve\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score                          \n",
    "\n",
    "def get_roc_curve(label, scores, names):\n",
    "    \"\"\"Generates ROC Curves for a given array\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        fpr, tpr, thresholds = roc_curve(label, scores[i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr,\n",
    "                 tpr,\n",
    "                 linewidth=3,\n",
    "                 #linestyle=line_styles[0],\n",
    "                 label=(\"%s AUC: %s\" % (names[i], roc_auc)))\n",
    "        \n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylabel(\"Sensitivity (TPR)\")\n",
    "    plt.xlabel(\"Fall-out (TNR)\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlim([0, 1])\n",
    "    plt.title('ROC curves for different types of activation functions')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_dir_01 = '/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01/'\n",
    "files_dir_08 = '/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split08/'\n",
    "\n",
    "files_dir = files_dir_01\n",
    "\n",
    "ae_pred = pickle.load(open(files_dir + \"ae_pred.p\", \"rb\"))\n",
    "ae_pred_no_reg = pickle.load(open(files_dir + \"ae_pred_no_reg.p\", \"rb\"))\n",
    "ms_scores = pickle.load(open(files_dir + \"ms_scores.p\", \"rb\"))\n",
    "rf_scores = pickle.load(open(files_dir + \"rf_scores.p\", \"rb\"))\n",
    "true_labels = pickle.load(open(files_dir + \"true_labels.p\", \"rb\"))\n",
    "luminosity = pickle.load(open(files_dir + \"luminosity.p\", \"rb\"))\n",
    "X_test = pickle.load(open(files_dir + \"x_test.p\", \"rb\"))\n",
    "\n",
    "true_labels = true_labels[0]\n",
    "ms_scores = ms_scores[0]\n",
    "rf_scores = rf_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_softmax/\"\n",
    "\n",
    "ae_error_softmax = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_elu/\"\n",
    "\n",
    "ae_error_elu = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_selu/\"\n",
    "\n",
    "ae_error_selu = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_softplus/\"\n",
    "\n",
    "ae_error_softplus = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_softsign/\"\n",
    "\n",
    "ae_error_softsign = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_relu/\"\n",
    "\n",
    "ae_error_relu = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_sigmoid/\"\n",
    "\n",
    "ae_error_sigmoid = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_hard_sigmoid/\"\n",
    "\n",
    "ae_error_hard_sigmoid = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_tanh/\"\n",
    "\n",
    "ae_error_tanh = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/lumi_dep/split01_linear/\"\n",
    "\n",
    "ae_error_linear = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/batch_norm/\"\n",
    "\n",
    "ae_error_prelu_batch_norm = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_dir = \"/eos/user/t/tkrzyzek/autoencoder/visualization/\"\n",
    "\n",
    "ae_error_cleaned = pickle.load(open(files_dir + \"ae_error.p\", \"rb\"))\n",
    "y_test_cleaned = pickle.load(open(files_dir + \"y_test.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error_df(X_test, predictions, mode=\"allmean\", n_highest = 100):\n",
    "    \n",
    "    if mode == \"allmean\":\n",
    "        return np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "    \n",
    "    elif mode == \"topn\":\n",
    "        temp = np.partition(-np.power(X_test - predictions, 2), n_highest)\n",
    "        result = -temp[:,:n_highest]\n",
    "        return np.mean(result, axis=1)\n",
    "    \n",
    "    elif mode == \"perobj\":\n",
    "        mses = []\n",
    "        for l in legend:\n",
    "            mse = np.mean(\n",
    "                np.power(X_test[:,l[\"start\"]:l[\"end\"]] - predictions[:,l[\"start\"]:l[\"end\"]], 2),\n",
    "                axis=1)\n",
    "            mses.append(mse)\n",
    "     \n",
    "        return np.maximum.reduce(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit\n",
    "ae_scores = get_error_df(X_test, ae_pred, mode=\"topn\")\n",
    "ae_scores_no_reg = get_error_df(X_test, ae_pred_no_reg, mode=\"topn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"PReLU\", \n",
    "#          \"Autoencoder wo regularization\",\n",
    "         \"PReLU cleaned input\",\n",
    "         \"PReLU w/ batch normalization\"\n",
    "         \"softmax\",\n",
    "         \"elu\",\n",
    "         \"selu\",\n",
    "         \"softplus\",\n",
    "         \"softsign\",\n",
    "         \"relu\",\n",
    "         \"tanh\",\n",
    "         \"sigmoid\",\n",
    "         \"hard_sigmoid\",\n",
    "         \"linear\",\n",
    "         \"Mean square\", \n",
    "         \"Random forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inliers = len(X_test[true_labels == 0])\n",
    "outliers = len(X_test[true_labels == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_roc_curve(y_test_cleaned, [ae_error_cleaned], ['cleaned AE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Good lumis:\", inliers)\n",
    "print(\"Bad lumis:\", outliers)\n",
    "print(\"Ratio of bad lumis:\", outliers/len(true_labels))\n",
    "get_roc_curve(true_labels, \n",
    "              [ae_scores, \n",
    "#                ae_scores_no_reg, \n",
    "               ae_error_cleaned,\n",
    "               ae_error_prelu_batch_norm,\n",
    "               ae_error_softmax, \n",
    "               ae_error_elu,\n",
    "               ae_error_selu,\n",
    "               ae_error_softplus,\n",
    "               ae_error_softsign,\n",
    "               ae_error_relu,\n",
    "               ae_error_tanh,\n",
    "               ae_error_sigmoid,\n",
    "               ae_error_hard_sigmoid,\n",
    "               ae_error_linear,\n",
    "               ms_scores, \n",
    "               rf_scores],\n",
    "              names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save for later\n",
    "FIRST_LUMI = 130947\n",
    "\n",
    "# Index from zero\n",
    "luminosity = luminosity.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_lumis():\n",
    "    lumi_df = pd.DataFrame({'luminosity': luminosity,\n",
    "                           'true_label': true_labels})\n",
    "    \n",
    "    print(lumi_df[start:end].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pred_vs_feature(y_val, x_val, y_class, y_name=\"\", x_name=\"\", selected=[], linear=False,\n",
    "                    limit=False):\n",
    "    '''\n",
    "    Plots two arbitrary values agains each other.\n",
    "    '''\n",
    "    df = pd.DataFrame({'y_val': y_val,\n",
    "                       'x_val': x_val,\n",
    "                       'y_class': y_class})\n",
    "\n",
    "    groups = df.groupby('y_class')\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x_val, \n",
    "                group.y_val,\n",
    "                color=\"red\" if name == 1 else \"blue\",\n",
    "                marker='o',\n",
    "                ms=2,\n",
    "                linestyle='',\n",
    "                label= \"Anomaly\" if name == 1 else \"Normal\")\n",
    "\n",
    "    for i in selected:\n",
    "        ax.plot(x_val[i],\n",
    "                y_val[i],\n",
    "                color=\"green\",\n",
    "                marker='o',\n",
    "                ms=4,\n",
    "                linestyle='')\n",
    "                 \n",
    "    ax.legend()\n",
    "    if not linear:\n",
    "        ax.set_yscale('log')\n",
    "    if limit:\n",
    "        plt.xlim([limit[0], limit[1]])\n",
    "    plt.grid()\n",
    "    plt.ylabel(y_name)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luminosity across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(luminosity, range(len(true_labels)), true_labels, \"Luminosity\", \n",
    "                \"Lumisection #\", linear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction error across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ae_scores, range(len(true_labels)), true_labels, \"AE reco error\", \n",
    "                \"Lumisection #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ae_scores_no_reg, range(len(true_labels)), true_labels, \"AE reco error\", \n",
    "                \"Lumisection #\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to select lumisections range of the bad lumis cluster. Selected lumisections are marked in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin = 1850\n",
    "end = 2150\n",
    "\n",
    "lumis_range = range(begin, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ae_scores, range(len(true_labels)), true_labels, \"AE reco error\", \n",
    "                \"Lumisection #\", selected=lumis_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected lumisections' luminosity (again in green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(luminosity, range(len(true_labels)), true_labels, \"Luminosity\", \n",
    "                \"Lumisection #\", linear=True, selected=lumis_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom in to the selected range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(luminosity, range(len(true_labels)), true_labels, \"Luminosity\", \n",
    "                \"Lumisection #\", linear=True, selected=lumis_range, limit=(begin, end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of luminosity of the selected lumisections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(luminosity[begin:end], bins=np.arange(0, 0.4, 0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction error vs luminosity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is plot of AE reconstruction error vs luminosity (the 'banana' in Filip's presentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ms_scores, luminosity, true_labels, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ae_scores_no_reg, luminosity, true_labels, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ae_scores, luminosity, true_labels, \"AE reco error\", \"Luminosity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... with the cluster selected above marked in green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_feature(ae_scores, luminosity, true_labels, \"AE reco error\", \"Luminosity\",\n",
    "               lumis_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP = 0.05\n",
    "#SAMPLE_SIZE = 2377\n",
    "SAMPLE_SIZE=100\n",
    "\n",
    "features_good = []\n",
    "features_bad = []\n",
    "\n",
    "def plot_mean_features(X, y):\n",
    "    \n",
    "    lower_bounds = np.arange(0, 0.35, STEP)\n",
    "    \n",
    "    for i in lower_bounds:\n",
    "        data_filtered = data[(data['inst_lumi'] >= i) & (data['inst_lumi'] <= i+STEP)]\n",
    "        print(i, \"-\", i+STEP)\n",
    "        \n",
    "        print(\"Dataset size:\", len(data_filtered))\n",
    "        X = data_filtered.iloc[:, 0:2806]\n",
    "        X_good = X[y == 0]\n",
    "        X_bad = X[y == 1]\n",
    "        print(\"Good samples:\", len(X_good))\n",
    "        print(\"Bad samples:\", len(X_bad))\n",
    "        \n",
    "        if len(X_bad) == 0:\n",
    "            continue\n",
    "        \n",
    "        sample_good = X_good.sample(SAMPLE_SIZE)\n",
    "        bad_sample = X_bad.sample(SAMPLE_SIZE)\n",
    "        \n",
    "        good_mean = abs(np.mean(sample_good, axis=0))\n",
    "        bad_mean = abs(np.mean(bad_sample, axis=0))\n",
    "        \n",
    "        good_median = abs(np.median(sample_good, axis=0))\n",
    "        bad_median = abs(np.median(bad_sample, axis=0))\n",
    "        \n",
    "        print(\"GOOD lumi abs mean of mean of features:\", np.mean(good_mean))\n",
    "        print(\"BAD  lumi abs mean of mean of features:\", np.mean(bad_mean))\n",
    "        print(\"===============================================================\")\n",
    "        print(\"GOOD lumi abs median of mean of features:\", np.median(good_mean))\n",
    "        print(\"BAD  lumi abs median of mean of features:\", np.median(bad_mean))\n",
    "        print(\"===============================================================\")\n",
    "        print(\"GOOD lumi abs mean of median of features:\", np.mean(good_median))\n",
    "        print(\"BAD  lumi abs mean of median of features:\", np.mean(bad_median))\n",
    "        print(\"===============================================================\")\n",
    "        print(\"GOOD lumi abs median of median of features:\", np.median(good_median))\n",
    "        print(\"BAD  lumi abs median of median of features:\", np.median(bad_median))\n",
    "    \n",
    "        fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "        \n",
    "        ax1.plot(np.array([i for i in range(len(bad_mean))]),\n",
    "                 bad_mean,\n",
    "                 color=\"red\",\n",
    "                 linestyle='-',\n",
    "                 ms=2,\n",
    "                 marker='o')\n",
    "                 \n",
    "        ax1.plot(np.array([i for i in range(len(good_mean))]),\n",
    "                 good_mean,\n",
    "                 color=\"green\",\n",
    "                 linestyle='-',\n",
    "                 ms=2,\n",
    "                 marker='o')\n",
    "        \n",
    "        ax2.plot(np.array([i for i in range(len(bad_median))]),\n",
    "                 bad_median,\n",
    "                 color=\"red\",\n",
    "                 linestyle='-',\n",
    "                 ms=2,\n",
    "                 alpha=0.9,\n",
    "                 marker='o')\n",
    "                 \n",
    "        ax2.plot(np.array([i for i in range(len(good_median))]),\n",
    "                 good_median,\n",
    "                 color=\"green\",\n",
    "                 linestyle='-',\n",
    "                 alpha=0.9,\n",
    "                 ms=2,\n",
    "                 marker='o')\n",
    "        \n",
    "        ax1.set_title(\"Mean\")\n",
    "        ax2.set_title(\"Median\")\n",
    "        \n",
    "        #plt.xlim([0, 100])\n",
    "        #plt.ylim([-5, 5])\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.xlabel(\"Feature #\")\n",
    "        plt.show()\n",
    "        \n",
    "        fig2, (ax3, ax4) = plt.subplots(2, sharex=True)\n",
    "        \n",
    "        ax3.hlines(np.mean(good_mean), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#16ff02\", \n",
    "                   zorder=100, \n",
    "                   label='GOOD lumi abs mean of mean')\n",
    "        \n",
    "        ax3.hlines(np.mean(bad_mean), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#ff0000\", \n",
    "                   zorder=100, \n",
    "                   label='BAD  lumi abs mean of mean')\n",
    "        \n",
    "        ax3.hlines(np.median(good_mean), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#005611\", \n",
    "                   zorder=100, \n",
    "                   label='GOOD lumi abs median of mean')\n",
    "        \n",
    "        ax3.hlines(np.median(bad_mean), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#560000\", \n",
    "                   zorder=100, \n",
    "                   label='BAD  lumi abs median of mean')\n",
    "        \n",
    "        ax4.hlines(np.mean(good_median), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#16ff02\", \n",
    "                   zorder=100, \n",
    "                   label='GOOD lumi abs mean of median')\n",
    "        \n",
    "        ax4.hlines(np.mean(bad_median), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#ff0000\", \n",
    "                   zorder=100, \n",
    "                   label='BAD  lumi abs mean of median')\n",
    "        \n",
    "        ax4.hlines(np.median(good_median), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#005611\", \n",
    "                   zorder=100, \n",
    "                   label='GOOD lumi abs median of median')\n",
    "        \n",
    "        ax4.hlines(np.median(bad_median), \n",
    "                   ax1.get_xlim()[0], \n",
    "                   ax1.get_xlim()[1], \n",
    "                   colors=\"#560000\", \n",
    "                   zorder=100, \n",
    "                   label='BAD  lumi abs median of median')\n",
    "        \n",
    "        #ax3.set_ylim([0, 1.5])\n",
    "        #ax4.set_ylim([0, 1.5])\n",
    "        ax3.legend()\n",
    "        ax4.legend()\n",
    "    \n",
    "plot_mean_features(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
